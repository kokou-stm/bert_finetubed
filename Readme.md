# Fine-Tuning d'un LLM sur le Dataset IMDB

Ce projet prÃ©sente un exemple complet de fine-tuning dâ€™un modÃ¨le de langage prÃ©-entraÃ®nÃ© (comme `DistilBERT`) sur le dataset IMDB pour la classification de sentiments (positif/nÃ©gatif).

## ğŸ§° FonctionnalitÃ©s principales

- Chargement et prÃ©traitement du dataset IMDB
- Utilisation de la bibliothÃ¨que `datasets` de Hugging Face
- Tokenization avec `AutoTokenizer`
- Fine-tuning dâ€™un modÃ¨le `AutoModelForSequenceClassification`
- Ã‰valuation des performances avec `accuracy`, `f1`, etc.
- Sauvegarde et chargement du modÃ¨le fine-tunÃ©

## ğŸ› ï¸ Librairies utilisÃ©es

- `transformers`
- `datasets`
- `evaluate`
- `scikit-learn`
- `torch`

## ğŸš€ Instructions de dÃ©marrage

1. Cloner ce dÃ©pÃ´t ou tÃ©lÃ©charger le notebook.
2. Installer les dÃ©pendances :

```bash
pip install transformers datasets evaluate scikit-learn torch
## ğŸš€ Instructions d'utilisation

Lancer le notebook `FineTuningLLM_with_IMDB_Dataset.ipynb`.

Suivre les Ã©tapes pour :

- PrÃ©parer les donnÃ©es
- EntraÃ®ner le modÃ¨le
- Ã‰valuer et sauvegarder les rÃ©sultats

## ğŸ“Š RÃ©sultats

Le modÃ¨le atteint une prÃ©cision et une F1-score compÃ©titives sur l'ensemble de test du jeu de donnÃ©es IMDB, dÃ©montrant l'efficacitÃ© du fine-tuning avec les LLM.

## ğŸ“ Fichiers

- `FineTuningLLM_with_IMDB_Dataset.ipynb` : Notebook principal avec tout le code.
- `model/` : Dossier prÃ©vu pour sauvegarder le modÃ¨le fine-tunÃ© (crÃ©Ã© automatiquement).

## ğŸ“ Auteurs

Ce projet a Ã©tÃ© rÃ©alisÃ© Ã  titre pÃ©dagogique pour illustrer le fine-tuning de modÃ¨les de langage avec Hugging Face.
